[tool.poetry]
name = "qa-eval"
version = "2.1.2"
description = "For assessing question answering systems' final answers and intermediate steps, against a given set of questions, reference answers and steps."
authors = []
readme = "README.md"
license = "Apache-2.0"
repository = "https://github.com/Ontotext-AD/qa-eval"

[tool.poetry.dependencies]
conda-lock = "3.0.1"
python = "3.12.10"
pip = "25.1.1"

[tool.poetry.group.test.dependencies]
pytest = "8.3.5"
pytest-cov = "6.1.1"
jsonlines = "4.0.0"

[tool.poetry.group.test]
optional = true

[build-system]
requires = ["poetry-core>=1.0.0"]
build-backend = "poetry.core.masonry.api"
